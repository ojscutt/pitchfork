{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7f45800-5955-41a6-b897-946ae31fb60f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-05 17:10:04.114254: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-09-05 17:10:04.125653: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-09-05 17:10:04.129182: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-09-05 17:10:04.771865: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "import scipy\n",
    "from scipy import constants\n",
    "from scipy import stats\n",
    "import astropy.constants\n",
    "\n",
    "\n",
    "from wtf import wtf_compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "326b0bbe-9098-402b-8a4a-7ad84dad57d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pitchfork/pitchfork.json', 'r') as fp:\n",
    "    pitchfork_dict = json.load(fp)\n",
    "\n",
    "pitchfork = wtf_compile(pitchfork_dict, jaxxed=False)\n",
    "\n",
    "with open('pitchfork/pitchfork_info.json', 'r') as fp:\n",
    "    pitchfork_info = json.load(fp)\n",
    "\n",
    "pitchfork_cov = np.loadtxt('pitchfork/pitchfork_covariance.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5aa9b96-4f60-4deb-8c2b-6d49bbe1ced9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_comps = np.array(pitchfork_info['custom_objects']['inverse_pca']['pca_comps'])\n",
    "pca_mean = np.array(pitchfork_info['custom_objects']['inverse_pca']['pca_mean'])\n",
    "\n",
    "\n",
    "def pcann(x, jaxxed=False):\n",
    "    if jaxxed:\n",
    "        y = jnp.tensordot(x, pca_comps, 1) + pca_mean\n",
    "        return y\n",
    "    else:\n",
    "        y = np.tensordot(x, pca_comps, 1) + pca_mean\n",
    "        return y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f2306df-7d0d-4211-8bac-180cfdb88f03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 2.16970188e+00, -2.69331376e-02, -2.68745388e-02,\n",
       "         -5.39015889e-03,  4.58675991e-03, -1.58866712e-03,\n",
       "          3.01504437e-03,  1.99272068e-03, -1.26795136e-04,\n",
       "          1.98271638e-03,  1.32488493e-03,  1.57268512e-03,\n",
       "          2.23839220e-05,  5.42823507e-04, -3.67025738e-03]]),\n",
       " array([[5.34786024, 3.61132239, 1.03881122]])]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = pitchfork.forward(np.array([[0.5,0.5,0.5,0.5,0.5]]))\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8edc1e45-f693-4e3e-ac2b-ded23d2b8cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pcann(x, jaxxed=False):\n",
    "    if jaxxed:\n",
    "        y = jnp.tensordot(x, pca_comps, 1) + pca_mean\n",
    "        return y\n",
    "    else:\n",
    "        y = np.tensordot(x, pca_comps, 1) + pca_mean\n",
    "        return y\n",
    "\n",
    "\n",
    "def predict(x, emulator, jaxxed=False):\n",
    "    if jaxxed:\n",
    "        pass\n",
    "    else:\n",
    "        log_inputs_mean = np.array(pitchfork_info[\"data_scaling\"][\"inp_mean\"][0])\n",
    "        \n",
    "        log_inputs_std = np.array(pitchfork_info[\"data_scaling\"][\"inp_std\"][0])\n",
    "\n",
    "        log_outputs_mean = np.array(pitchfork_info[\"data_scaling\"][\"classical_out_mean\"][0] + pitchfork_info[\"data_scaling\"][\"astero_out_mean\"][0])\n",
    "        \n",
    "        log_outputs_std = np.array(pitchfork_info[\"data_scaling\"][\"classical_out_std\"][0] + pitchfork_info[\"data_scaling\"][\"astero_out_std\"][0])\n",
    "            \n",
    "        log_inputs = np.log10(x)\n",
    "        \n",
    "        standardised_log_inputs = (log_inputs - log_inputs_mean)/log_inputs_std\n",
    "\n",
    "        preds = pitchfork.forward(standardised_log_inputs)\n",
    "        \n",
    "        standardised_log_outputs = np.concatenate((np.array(preds[1]),np.array(pcann(preds[0]))), axis=1)\n",
    "\n",
    "        log_outputs = (standardised_log_outputs*log_outputs_std) + log_outputs_mean\n",
    "\n",
    "        outputs = 10**log_outputs\n",
    "\n",
    "        outputs[:,2] = log_outputs[:,2] ##we want star_feh in dex\n",
    "\n",
    "        # teff = np.array(((outputs[:,1]*astropy.constants.L_sun) / (4*np.pi*constants.sigma*((outputs[:,0]*astropy.constants.R_sun)**2)))**0.25)\n",
    "        \n",
    "        # outputs[:,0] = teff\n",
    "        \n",
    "        # #outputs = np.concatenate((np.array(outputs[:,:3]), np.array(outputs[:,n_min-3:n_max-2])), axis=1)\n",
    "\n",
    "        return outputs\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "fdd323db-de5a-4d9e-8c56-961ad0b2ea5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.69203956e+28, 2.58278194e+36, 3.66121808e+01, 7.98343758e-04,\n",
       "        8.27478264e+01, 2.98534905e+01, 3.09840047e+03, 1.69057150e+04,\n",
       "        3.39187159e+01, 2.46668441e-01, 1.94838973e+00, 1.01935737e+02,\n",
       "        1.47973240e+02, 2.33913783e+01, 1.82341612e+01, 1.44833682e+02,\n",
       "        1.67798033e+03, 5.34928744e+03, 4.20138033e+03, 2.08572397e+03,\n",
       "        1.31815286e+03, 1.47132625e+03, 3.22099318e+03, 7.15133084e+03,\n",
       "        5.22700231e+03, 1.90555167e+03, 2.27872553e+03, 1.96758277e+04,\n",
       "        2.44156811e+05, 3.89735928e+05, 3.77836413e+04, 1.33173966e+03,\n",
       "        1.91749251e+02, 2.62525315e+02, 1.01727011e+03, 2.32002517e+03,\n",
       "        2.24504708e+03, 1.74631346e+03]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(np.array([[0.5,0.5,0.5,0.5,0.5]]), pitchfork)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4b42ba-120c-4938-9cec-7705ab782382",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InversePCA(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    Inverse PCA layer for tensorflow neural network\n",
    "    \n",
    "    Usage:\n",
    "        - Define dictionary of custom objects containing Inverse PCA\n",
    "        - Use arguments of PCA mean and components from PCA of output parameters for inverse PCA (found in JSON dict)\n",
    "        \n",
    "    Example:\n",
    "\n",
    "    > f = open(\"pcann_info.json\")\n",
    "    >\n",
    "    > data = json.load(f)\n",
    "    >\n",
    "    > pca_comps = np.array(data[\"pca_comps\"])\n",
    "    > pca_mean = np.array(data[\"pca_mean\"])\n",
    "    > \n",
    "    > custom_objects = {\"InversePCA\": InversePCA(pca_comps, pca_mean)}\n",
    "    > pcann_model = tf.keras.models.load_model(\"pcann_name.h5\", custom_objects=custom_objects)\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, pca_comps, pca_mean, **kwargs):\n",
    "        super(InversePCA, self).__init__()\n",
    "        self.pca_comps = pca_comps\n",
    "        self.pca_mean = pca_mean\n",
    "        \n",
    "    def call(self, x):\n",
    "        y = tf.tensordot(x, np.float32(self.pca_comps),1) + np.float32(self.pca_mean)\n",
    "        return y\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super().get_config().copy()\n",
    "        config.update({\n",
    "            'pca_comps': self.pca_comps,\n",
    "            'pca_mean': self.pca_mean\n",
    "        })\n",
    "        return config\n",
    "\n",
    "class WMSE(tf.keras.losses.Loss):\n",
    "    \"\"\"\n",
    "    Weighted Mean Squared Error Loss Function for tensorflow neural network\n",
    "    \n",
    "    Usage:\n",
    "        - Define list of weights with len = labels\n",
    "        - Use weights as arguments - no need to square, this is handled in-function\n",
    "        - Typical usage - defining target precision on outputs for the network to achieve, weights parameters in loss calculation to force network to focus on parameters with unc >> weight.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, weights, name = \"WMSE\",**kwargs):\n",
    "        super(WMSE, self).__init__()\n",
    "        self.weights = np.float32(weights)\n",
    "        \n",
    "    def call(self, y_true, y_pred):\n",
    "        loss = ((y_true - y_pred)/(self.weights))**2\n",
    "        return tf.math.reduce_mean(loss)\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super().get_config().copy()\n",
    "        config.update({\n",
    "            'weights': self.weights\n",
    "        })\n",
    "        return config\n",
    "\n",
    "def WMSE_metric(y_true, y_pred):\n",
    "    metric = ((y_true - y_pred)/(weights))**2\n",
    "    return tf.reduce_mean(metric)\n",
    "\n",
    "\n",
    "class emulator:\n",
    "    def __init__(self, emulator_name, file_path='pitchfork/'):\n",
    "        self.emulator_name = emulator_name\n",
    "        self.file_path = file_path + self.emulator_name\n",
    "        \n",
    "        with open(self.file_path+\".pkl\", 'rb') as fp:\n",
    "             self.emulator_dict = pickle.load(fp)\n",
    "\n",
    "        self.log_inputs_mean = np.array(self.emulator_dict[\"data_scaling\"][\"inp_mean\"][0])\n",
    "        \n",
    "        self.log_inputs_std = np.array(self.emulator_dict[\"data_scaling\"][\"inp_std\"][0])\n",
    "\n",
    "        self.log_outputs_mean = np.array(self.emulator_dict[\"data_scaling\"][\"classical_out_mean\"][0] + self.emulator_dict[\"data_scaling\"][\"astero_out_mean\"][0])\n",
    "        \n",
    "        self.log_outputs_std = np.array(self.emulator_dict[\"data_scaling\"][\"classical_out_std\"][0] + self.emulator_dict[\"data_scaling\"][\"astero_out_std\"][0])\n",
    "            \n",
    "        self.custom_objects = {\"InversePCA\": InversePCA(self.emulator_dict['custom_objects']['inverse_pca']['pca_comps'], self.emulator_dict['custom_objects']['inverse_pca']['pca_mean']),\"WMSE\": WMSE(self.emulator_dict['custom_objects']['WMSE']['weights'])}\n",
    "\n",
    "        self.model = tf.keras.models.load_model(self.file_path+\".h5\", custom_objects=self.custom_objects)\n",
    "\n",
    "        [print(str(key).replace(\"log_\",\"\") + \" range: \" + \"[min = \" + str(self.emulator_dict['parameter_ranges'][key][\"min\"]) + \", max = \" + str(self.emulator_dict['parameter_ranges'][key][\"max\"]) + \"]\") for key in self.emulator_dict['parameter_ranges'].keys()];\n",
    "\n",
    "    def predict(self, input_data, n_min=6, n_max=40, verbose=False):\n",
    "        \n",
    "        log_inputs = np.log10(input_data)\n",
    "        \n",
    "        standardised_log_inputs = (log_inputs - self.log_inputs_mean)/self.log_inputs_std\n",
    "\n",
    "        standardised_log_outputs = self.model(standardised_log_inputs)\n",
    "\n",
    "        standardised_log_outputs = np.concatenate((np.array(standardised_log_outputs[0]),np.array(standardised_log_outputs[1])), axis=1)\n",
    "\n",
    "        log_outputs = (standardised_log_outputs*self.log_outputs_std) + self.log_outputs_mean\n",
    "\n",
    "        outputs = 10**log_outputs\n",
    "\n",
    "        outputs[:,2] = log_outputs[:,2] ##we want star_feh in dex\n",
    "\n",
    "        teff = np.array(((outputs[:,1]*astropy.constants.L_sun) / (4*np.pi*constants.sigma*((outputs[:,0]*astropy.constants.R_sun)**2)))**0.25)\n",
    "        \n",
    "        outputs[:,0] = teff\n",
    "        \n",
    "        outputs = np.concatenate((np.array(outputs[:,:3]), np.array(outputs[:,n_min-3:n_max-2])), axis=1)\n",
    "\n",
    "        return outputs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
