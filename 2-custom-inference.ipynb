{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ddd74d98-ab81-45d0-8f56-b567cbfe3eb6",
   "metadata": {},
   "source": [
    "# 2) Custom Inference\n",
    "The previous notebook, `1-simple-inference.ipynb` showed how to quickly run inference with the `pitchfork_sampler` default setup.\n",
    "\n",
    "In reality, we can tune parts of the sampling pipeline described in the paper, which I'll split into three parts:\n",
    "1. Priors\n",
    "2. `UltraNest` parameters\n",
    "3. Surface term GP parameters\n",
    "\n",
    "By default, `pitchfork_sampler` will use:\n",
    "1. The priors used in the paper, which are bounded to the trained ranges of `pitchfork`\n",
    "2. The `UltraNest` defaults (with the exception of `ndraw_min` and `ndraw_max`, which we'll get to later)\n",
    "3. The GP variance and lengthscale factor used in the paper for sampling Solar fundamental properties (`gp_var = 4` and `gp_ls_factor=7`, respectively).\n",
    "\n",
    "In many cases, these defaults should work well (and are safe!). Regardless, here I'll show you how to customise some of these properties if, for instance, you want to restrict your priors for a given star, or turn down `ndraw_max` so the sampler doesn't OOM your laptop.\n",
    "\n",
    "At the end, I'll show how to tweak the sampler to work for your own stars instead of using the defaults (which are chosen to work well on Solar data), by going through examples with 16 Cyg A and B.\n",
    "\n",
    "We'll start with **1. Priors**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9efa3d9d-51a1-4a3d-b286-7635c46b1ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import corner\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scripts import pitchfork_compile, pitchfork_sampler, posterior_plot\n",
    "\n",
    "### compile pitchfork\n",
    "\n",
    "with open('pitchfork/pitchfork.json', 'r') as fp:\n",
    "    pitchfork_dict = json.load(fp)\n",
    "\n",
    "with open('pitchfork/pitchfork_info.json', 'r') as fp:\n",
    "    pitchfork_info = json.load(fp)\n",
    "\n",
    "pitchfork_cov = np.loadtxt('pitchfork/pitchfork_covariance.txt')\n",
    "\n",
    "pitchfork = pitchfork_compile(pitchfork_dict, pitchfork_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3002ac2-052a-4798-870a-67045a6b793e",
   "metadata": {},
   "source": [
    "## 1. Priors\n",
    "Before, we initialised the sampler without specifying our prior beforehand which means we fall back to the default priors use in the paper:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040a7bca-bd69-4136-b19d-f4f374b1072c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = pitchfork_sampler(pitchfork, pitchfork_cov)\n",
    "\n",
    "priors = sampler.priors\n",
    "\n",
    "labels = ['initial_mass', 'initial_Zinit', 'initial_Yinit', 'initial_MLT', 'star_age', 'a', 'b']\n",
    "\n",
    "size = 10000\n",
    "prior_samples = np.array([prior.rvs(size=size) for prior in priors])\n",
    "\n",
    "corner.corner(prior_samples.T, color='black', labels = labels, hist_kwargs={'density':True}, smooth=True);\n",
    "plt.suptitle('prior samples')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "042ce6bf-7575-4e7d-812b-a29b650975f9",
   "metadata": {},
   "source": [
    "I leave these as defaults partly because they'll work fine in many cases, but much more importantly:\n",
    "\n",
    "**!!! NEURAL NETWORKS DO SILLY THINGS OUTSIDE THE BOUNDS OF THEIR TRAINING DATA - YOU HAVE BEEN WARNED !!!**\n",
    "\n",
    "Read the paper to find out more, but in short - these priors were chosen specifically to stop `pitchfork` from being asked to predict for inputs that fall outside of the trained range of the grid.\n",
    "\n",
    "Outside of this trained range, interpolation becomes extrapolation. `pitchfork` will start making wacky predictions (I'm talking $L_\\text{pred}=1\\times10^{64}\\,L_{\\odot}$, $T_\\text{pred}=1\\times10^{-6}\\,\\text{K}$ levels of wacky) that are in no way represented by the summary statistic for `pitchfork` precision that we use to define the likelihood function.\n",
    "\n",
    "That being said, it's fine to *restrict* the prior ranges to within the trained range of `pitchfork` if you need to, or change the functional form of the priors. Also, given that `pitchfork` is only trained on the fundamental properties (`initial_mass`, `initial_Zinit`, `initial_Yinit`, `initial_MLT`, `star_age`) you're free to change the ranges on the surface term parameters `a` and `b` as much as you like.\n",
    "\n",
    "I've included some helper functions in `utils.py` for making beta and uniform priors like we do in the paper - I recommend sticking to these because you can specify hard limits for the prior to avoid `pitchfork` extrapolation, but feel free to restrict the range or mess with the shape parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d557d66-ee53-4214-b36e-28a5104da144",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts import beta_prior, uniform_prior\n",
    "# beta_prior(min, max, a, b)\n",
    "# uniform_prior(min, max)\n",
    "\n",
    "mass_prior = uniform_prior(0.95, 1.05) #<- default: beta_prior(0.8, 1.2, a=5, b=2)\n",
    "\n",
    "Zinit_prior = uniform_prior(0.008, 0.02) #<- default: beta_prior(0.004, 0.038, a=2, b=5)\n",
    "\n",
    "Yinit_prior = uniform_prior(0.25, 0.28) #<- default: beta_prior(0.24, 0.32, a=2, b=5)\n",
    "\n",
    "MLT_prior = uniform_prior(2.1, 2.2) #<- default: beta_prior(1.7, 2.5, a=1.2, b=1.2)\n",
    "\n",
    "age_prior = uniform_prior(2, 6) #<- default: beta_prior(0.03, 14, a=1.2, b=1.2)\n",
    "\n",
    "a_prior = uniform_prior(-4, 0) #<- default: uniform_prior(-10, 2)\n",
    "\n",
    "b_prior = uniform_prior(3.8, 5.5) #<- default: uniform_prior(4.4, 5.25)\n",
    "\n",
    "custom_priors = [mass_prior, Zinit_prior, Yinit_prior, MLT_prior, age_prior, a_prior, b_prior]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8c7afe-723c-48dd-8c4c-72285a03234a",
   "metadata": {},
   "source": [
    "Having defined our custom priors, we just pass them to the `pitchfork_sampler` object along with `pitchfork` when initialising and then we can sample and plot as before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e092b1f2-ac01-4326-96fa-75d759a8a263",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = pitchfork_sampler(pitchfork, pitchfork_cov, priors=custom_priors)\n",
    "\n",
    "priors = sampler.priors\n",
    "\n",
    "labels = ['initial_mass', 'initial_Zinit', 'initial_Yinit', 'initial_MLT', 'star_age', 'a', 'b']\n",
    "\n",
    "size = 10000\n",
    "prior_samples = np.array([prior.rvs(size=size) for prior in priors])\n",
    "\n",
    "corner.corner(prior_samples.T, color='black', labels = labels, hist_kwargs={'density':True}, smooth=True);\n",
    "plt.suptitle('prior samples')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5dc156-f1c7-43b4-9cfd-7d5b620ae7e3",
   "metadata": {},
   "source": [
    "Funky! But fine for `pitchfork` :)\n",
    "\n",
    "Let's see how a nested sampling run using these priors looks for the sun:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afcfd8e9-91a5-408e-8d1d-1187a533bbcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "star_name = 'Sun'\n",
    "\n",
    "results = sampler(star_name)\n",
    "\n",
    "posterior_plot(results, include_prior=True, star_name=star_name);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b81249-8fa6-4064-87be-1efe808b7d77",
   "metadata": {},
   "source": [
    "## 2. UltraNest parameters\n",
    "There are several parameters that we can tune within `UltraNest` that can change how our sampler behaves. I won't go into too much detail on what these actually do here - you can find that in the [docs](https://johannesbuchner.github.io/UltraNest/index.html).\n",
    "\n",
    "`pitchfork_sampler` will just use the `UltraNest` defaults for most of these, which will work well in many cases (but I'll show you how to tweak some of these later).\n",
    "\n",
    "The only ones that aren't the `UltraNest` defaults are `ndraw_min` and `ndraw_max`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d74866b-4343-4dd9-babf-e58975958a5f",
   "metadata": {},
   "source": [
    "### 2.1. `ndraw_min` and `ndraw_max`\n",
    "These parameters control the number of points that are proposed simultaneously by the sampler to be evaluated via the likelihood function.\n",
    "\n",
    "`UltraNest` starts by drawing at `ndraw_max`, and then will dynamically reduce the number of draws if the efficiency (see `eff` value in `UltraNest` readout) drops, to a lower limit of `ndraw_min`.\n",
    "\n",
    "The defaults are `ndraw_min=128` and `ndraw_max=65536`. The [docs](https://johannesbuchner.github.io/UltraNest/index.html) says for both of these parameters to \"*Increase this if your likelihood makes vectorization very cheap*\".\n",
    "\n",
    "**Our `pitchfork` likelihood makes vectorisation *very* cheap.**\n",
    "\n",
    "Therefore, I set the defaults to `ndraw_min=1024` and `ndraw_max=524288`.\n",
    "\n",
    "Even though `Ultranest` will rapidly drop from `ndraw_max` in a few iterations, it may be that these defaults are too intense for your machine. In that case, we can easily reduce like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb01c4d5-1142-42e8-95d2-d0d7042a114f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = pitchfork_sampler(pitchfork, pitchfork_cov)\n",
    "\n",
    "results = sampler('Sun',ndraw_min=512, ndraw_max=262144)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c143ebad-0f6d-4468-a576-e573820f43ba",
   "metadata": {},
   "source": [
    "This should still be reasonably fast, and may even be faster than the defaults if your machine was struggling with memory bottlenecks before.\n",
    "\n",
    "I'd avoid setting both `ndraw_min` and `ndraw_max` to high values, because the final stages of nested sampling take many many iterations in a small area of parameter space, within which making many draws is completely unneccassary (which is why `UltraNest` dynamically reduces the number of draws). It's best to have a wide range, like shown above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a502c8b7-6a38-48f2-9183-e99aca31189f",
   "metadata": {},
   "source": [
    "### 2.2. `frac_remain`\n",
    "Another `UltraNest` parameter which might come in handy is `frac_remain`, which defines the fraction of the integral left in the remainder at which `UltraNest` should stop sampling.\n",
    "\n",
    "I've left this at the default, `frac_remain=0.01`, which works well in many cases (the [docs](https://johannesbuchner.github.io/UltraNest/index.html) say that a higher number, like 0.5, is fine if we know the posterior is simple - which we'd expect for solar-like oscillators).\n",
    "\n",
    "However, there are a couple reasons why you might want to change this - for instance, if you're bugfixing and don't necessarily care about the sampler meaningfully constraining the posterior, you might want to set the `frac_remain` very high like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f2beb1-71fe-4c4c-b3cc-e6b11af8ad2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = pitchfork_sampler(pitchfork, pitchfork_cov)\n",
    "\n",
    "results = sampler('Sun',frac_remain=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5590993d-56f0-4d85-b551-4283102b5fe4",
   "metadata": {},
   "source": [
    "Fast!\n",
    "\n",
    "Or, if you'd like to make sure you've **really** found those peaks, you could set this very low (which may take quite a bit longer):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c775bd-e16f-42f1-b50d-db234e439b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = pitchfork_sampler(pitchfork, pitchfork_cov)\n",
    "\n",
    "results = sampler('Sun',frac_remain=1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28eeb0d2-39c0-4e58-929b-2f0af7cfc427",
   "metadata": {},
   "source": [
    "### 2.3. `min_num_live_points`\n",
    "One of the most common questions on nested sampler docs FAQs is: \"How many live points should I use?\". It seems like there isn't really an answer to this beyond: \"It completely depends on your problem, machine, and the complexity of the posterior.\"\n",
    "\n",
    "Put simply, the live points are the points in parameter space that are actively evaluated as the nested sampler progresses, and control the resolution of the posterior we return. Too few and we risk missing out on peaks in our posterior or ending up with jagged posterior distributions. Too many and our sampler takes an age to run and arrives at the same solutions that we'd have found by using fewer.\n",
    "\n",
    "The `UltraNest` default is 400, which I've left as the default for `pitchfork_sampler` too - this seems reasonable if we also follow the guidance in the [`dynesty` docs](https://dynesty.readthedocs.io/en/v3.0.0/faq.html#live-point-questions): \"*Around 50 * ndim points are recommended for each expected mode.*\". We are sampling over 7 dimensions, and don't necessarily expect our posteriors to be multimodal.\n",
    "\n",
    "That being said, it may be that the particular star you're sampling has a complex posterior, or your laptop struggles with `min_num_live_points=400`. Let's see what happens if we use just 10 live points:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0886b93e-040c-4d36-b0a5-522c53a98b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = pitchfork_sampler(pitchfork, pitchfork_cov)\n",
    "\n",
    "low_live_results = sampler('Sun', min_num_live_points = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc7c2f8-9e9d-4b53-9c49-8f87c06927a6",
   "metadata": {},
   "source": [
    "A few interesting things happened there!\n",
    "\n",
    "- Firstly, that was ridiculously fast!\n",
    "\n",
    "- Also, `UltraNest` immediately updated to 64 live points instead of the 10 we asked for with the message:\n",
    "    ```\n",
    "    [ultranest] To achieve the desired logz accuracy, min_num_live_points was increased to 64\n",
    "    ```\n",
    "    \n",
    "    This happens because `UltraNest` initialises with a target accuracy on the log evidence, `logz`, which is proportional to $1\\over{\\sqrt{N_{\\text{live}}}}$. If $N_{\\text{live}}$ is too low, this target cannot be reached, and `UltraNest` automatically increases.\n",
    "\n",
    "- After sampling with $N_{\\text{live}}=64$ for a while. `UltraNest` adds even more live points and prints a line like:\n",
    "    ```\n",
    "    [ultranest] Widening roots to 76 live points (have 64 already) ...\n",
    "    ```\n",
    "    This happens when `UltraNest` detects that the current number is insufficient for proper exploration of the likelihood surface. This is why the argument is `min_num_live_points` and not `num_live_points` - `UltraNest` automatically increases the number of live points if needed!\n",
    "\n",
    "- The final thing you might have noticed is that the live plot looked much more patchy than usual - these bars indicate roughly where in parameter space the live points are currently populated, and so it makes sense that using fewer live points means these plots are more jagged than with $N_{\\text{live}}=400$! However, the final position of the live points looks like they're evenly clustered around the peaks in the Solar posteriors that we've seen so far, which is a good sign.\n",
    "\n",
    "So if our sampling is *outrageously* fast when we set `min_num_live_points=10` and just let `UltraNest` decide how many live points to use, and the live points have still converged about the peaks of the posterior that we've seen when using `min_num_live_points=400`, why don't I just use 10 as the default?\n",
    "\n",
    "Let's check the posteriors we recieved from our most recent run:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857f6438-a9c5-454d-a3b3-7b4cef0f15c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior_plot(low_live_results, include_prior=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0490d06d-9316-4e8f-825a-5ee8cab8f34a",
   "metadata": {},
   "source": [
    "Despite having converged about values that agree with our previous posteriors, these posterior distributions are certainly not smooth with well defined peaks. In fact, they contain *far* fewer samples than our results when using `min_num_live_points=400`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dca2c98-de91-487c-b0bf-ec7e5aa96706",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'samples in posterior with min_num_live_points=10: {len(low_live_results[\"samples\"])}')\n",
    "\n",
    "print(f'samples in posterior with min_num_live_points=400: {len(results[\"samples\"])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5525ad84-5739-423b-bf6d-a175f0121d28",
   "metadata": {},
   "source": [
    "This is why it's probably best to stick with at least a few hundred live points - the extra minute it takes to sample is worth it for the smooth and well sampled posteriors we end up with :)\n",
    "\n",
    "That being said, it might be worth reducing from the default 400 if you're struggling with compute time or are just quickly checking that the sampler is capable of converging at all with your data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97b5516-61f7-4c81-b536-c09a526c6243",
   "metadata": {},
   "source": [
    "## 3. Surface term GP parameters\n",
    "Another feature of our sampler is a Gaussian Process (GP) correlated noise model.\n",
    "\n",
    "Please check the paper for a description on how/why we do this, and the `pitchfork_sampler` source code to see how I implement it, but there are two important parameters of the GP that determine the maximum flexibility (the **Variance**) and how quickly the functions can vary over the parameter space (the **lengthscale**).\n",
    "\n",
    "For our correlated noise model, the variance variable, `gp_var`, has units of $\\mu\\text{Hz}^{2}$, and the lengthscale, `gp_ls_factor` is defined as a factor of the large frequency separation $\\Delta\\nu$.\n",
    "\n",
    "The optimal choice for these is frequency-dependent, and thus varies on a star-by-star basis. Given we are interested in solar-like oscillators here, I set the default values to be those that we found optimal for the Sun in the sparse GP parameter gridsearch we carried out in the paper: `gp_var=4` and `gp_ls_factor=7` - these should work reasonably well for most stars in the parameter range we consider.\n",
    "\n",
    "However, if you'd like to change these, they can be passed as arguments to your sampler. I'll show an example here that varies `gp_var` and `gp_ls_factor` and compares the returned evidences (which are also stored in the dict returned by calling the sampler) to find which combination best describes the data (this may take a couple minutes):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a68850e-9f73-4149-91ff-13a58fb05222",
   "metadata": {},
   "outputs": [],
   "source": [
    "gp_vars = [4, 10]\n",
    "gp_ls_factors = [2, 7]\n",
    "\n",
    "print('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')\n",
    "print('Initiating GP parameter gridsearch:  ')\n",
    "print('')\n",
    "results_dict = {}\n",
    "for gp_var in gp_vars:\n",
    "    for gp_ls_factor in gp_ls_factors:\n",
    "        print(f'Sampling for gp_var={gp_var} and gp_ls_factor={gp_ls_factor}...')\n",
    "        print('')\n",
    "        sampler = pitchfork_sampler(pitchfork, pitchfork_cov)\n",
    "        results = sampler('Sun',\n",
    "                          gp_var=gp_var,\n",
    "                          gp_ls_factor=gp_ls_factor,\n",
    "                          frac_remain = 0.5, #<- earlier stopping criterion, see above\n",
    "                          viz_callback=False #<- this just turns off the live plots\n",
    "                         )\n",
    "        results_dict[f'var{gp_var}_ls{gp_ls_factor}'] = [results['logz'], results['logzerr']]\n",
    "        del results\n",
    "        print('')\n",
    "\n",
    "print('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')\n",
    "print('Done! Printing results of gridsearch:')\n",
    "print('')\n",
    "for gp_var in gp_vars:\n",
    "    for gp_ls_factor in gp_ls_factors:\n",
    "        logz, logzerr = results_dict[f'var{gp_var}_ls{gp_ls_factor}']\n",
    "        print(f'Evidence and error for gp_var={gp_var} and gp_ls_factor={gp_ls_factor}: {logz}, {logzerr}')\n",
    "        print('')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc94e2bc-add4-42f3-b9ea-e280eed61fa6",
   "metadata": {},
   "source": [
    "## 16 Cyg A & B \n",
    "Let's see how we can use the customisations above to run `pitchfork_sampler` on a stars that aren't the sun!\n",
    "\n",
    "The `/stars/...` folder should already contain data for 16 Cyg A - let's take a look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "649e17da-c0a3-4eac-bdb1-d15944f9983d",
   "metadata": {},
   "outputs": [],
   "source": [
    "star_name = '16CygA'\n",
    "\n",
    "with open(f'stars/{star_name}/{star_name}.json', 'r') as fp:\n",
    "    star_dict = json.load(fp)\n",
    "\n",
    "star_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f91c1604-0b03-4973-a014-04b1e36e82bc",
   "metadata": {},
   "source": [
    "Certainly not Solar!\n",
    "\n",
    "We'll use the GP parameters that we found to be optimal for 16 Cyg A in the paper:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a9dd04-5181-42f9-a555-b7ad30ab3ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = pitchfork_sampler(pitchfork, pitchfork_cov)\n",
    "\n",
    "A_results = sampler('16CygA', gp_var = 4, gp_ls_factor = 6, frac_remain=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f981d98d-f6cc-4835-9246-09f30030af5e",
   "metadata": {},
   "source": [
    "And now let's check the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1304aed5-c148-4d7f-8a32-b0e4b351af80",
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior_plot(A_results, color='#268BD2', include_prior=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56235c30-c946-4902-b64d-31c67c0586da",
   "metadata": {},
   "source": [
    "Nice! Now let's try the same for B so we can check whether we get the expected agreement between `initial_Zinit` and `star_age`..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58750713-98d4-4d3a-9681-230e42116e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "star_name = '16CygB'\n",
    "\n",
    "with open(f'stars/{star_name}/{star_name}.json', 'r') as fp:\n",
    "    star_dict = json.load(fp)\n",
    "\n",
    "star_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b219fa-a3fe-425d-922f-006a2c64f3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "B_results = sampler('16CygB', gp_var = 4, gp_ls_factor = 5, frac_remain=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d87fb4-abea-4982-b6fb-0c5f807909db",
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior_plot(B_results, color='#CB4B16', include_prior=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c01f42d2-ddec-42c3-818d-3d32b99640a7",
   "metadata": {},
   "source": [
    "The moment of truth! Let's plot these posteriors over one another to see whether we get agreement in the binary parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23edcb00-92d6-4119-8f87-550bf2eb2199",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = posterior_plot(A_results, color='#268BD2', include_prior=False);\n",
    "\n",
    "corner.corner(B_results['samples'], fig=fig, color = '#CB4B16', smooth=True, hist_kwargs={'density':True}, show_titles=False);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
